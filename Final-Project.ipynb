{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "---\r\n",
    "# Begin Analysis #"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "## ensembl REST API: loci associated with phenotype search\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "import requests, sys, random\r\n",
    "\r\n",
    "\r\n",
    "random.seed(13)\r\n",
    "\r\n",
    "def getloci(search_typ, term, source):\r\n",
    "## 1) NOTE Required to select values for search_typ, term\r\n",
    "    # search_typ = \"accession\" \r\n",
    "        ## ex. \"accession\" -> phenotype ontology accession; \r\n",
    "        ## ex. \"term\" -> phenotype ontology term  \r\n",
    "    # term = \"EFO:0004576\"\r\n",
    "        ## \"fetal hemoglobin\"\r\n",
    "        ## \"EFO:0004576\" ## fetal hemoglobin measurement\r\n",
    "        ## Orphanet:251380 ## Hereditary persistence of fetal hemoglobin-sickle cell disease syndrome\r\n",
    "\r\n",
    "## 2) NOTE Optional to filter by source; exact match\r\n",
    "    if source == 'GWAS':\r\n",
    "        source = \"NHGRI-EBI GWAS catalog\"\r\n",
    "        ## ex. \"NHGRI-EBI GWAS catalog\"; \"ClinVar\"\r\n",
    "\r\n",
    "    ext = \"http://rest.ensembl.org/phenotype/\" + str(search_typ) + \"/homo_sapiens/\" + str(term) + \"?source=\" + str(source)\r\n",
    "    \r\n",
    "    r = requests.get(ext, headers={ \"Content-Type\" : \"application/json\"})\r\n",
    "    \r\n",
    "    if not r.ok:\r\n",
    "        r.raise_for_status()\r\n",
    "        sys.exit()\r\n",
    "        ## error checking from ensembl REST API documentation\r\n",
    "    \r\n",
    "    decoded = r.json()\r\n",
    "    df = pd.json_normalize(decoded)\r\n",
    "        ## flatten json\r\n",
    "\r\n",
    "    df.rename(columns=(lambda x: x.replace('attributes.', '')), inplace=True)\r\n",
    "        ## rename columns for accessibility\r\n",
    "\r\n",
    "    df.dropna(subset=['beta_coefficient'], inplace=True)\r\n",
    "        ## drop rows with missing betas\r\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Return HPFH variants #"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df_hbf = getloci(\"accession\", \"EFO:0004576\", \"GWAS\")\r\n",
    "\r\n",
    "df_hbf = df_hbf[df_hbf['beta_coefficient'].str.contains('increase')]\r\n",
    "\r\n",
    "df_hbf.info()\r\n",
    "# df_hbf.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 276 entries, 1 to 601\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   description          276 non-null    object\n",
      " 1   Variation            276 non-null    object\n",
      " 2   mapped_to_accession  276 non-null    object\n",
      " 3   location             276 non-null    object\n",
      " 4   source               276 non-null    object\n",
      " 5   risk_allele          274 non-null    object\n",
      " 6   associated_gene      274 non-null    object\n",
      " 7   external_reference   276 non-null    object\n",
      " 8   beta_coefficient     276 non-null    object\n",
      " 9   p_value              276 non-null    object\n",
      " 10  odds_ratio           0 non-null      object\n",
      "dtypes: object(11)\n",
      "memory usage: 25.9+ KB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Return malaria resistant variants #"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df_mal = getloci(\"accession\", \"EFO:0001068\", \"GWAS\")\r\n",
    "\r\n",
    "df_mal = df_mal[df_mal['beta_coefficient'].str.contains('decrease')]\r\n",
    "\r\n",
    "# df_mal.head()\r\n",
    "df_mal.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 46 entries, 4 to 166\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   source               46 non-null     object\n",
      " 1   location             46 non-null     object\n",
      " 2   Variation            46 non-null     object\n",
      " 3   description          46 non-null     object\n",
      " 4   mapped_to_accession  46 non-null     object\n",
      " 5   associated_gene      46 non-null     object\n",
      " 6   external_reference   46 non-null     object\n",
      " 7   p_value              46 non-null     object\n",
      " 8   odds_ratio           0 non-null      object\n",
      " 9   risk_allele          0 non-null      object\n",
      " 10  beta_coefficient     46 non-null     object\n",
      "dtypes: object(11)\n",
      "memory usage: 4.3+ KB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Return rows with variants in common between datasets #\r\n",
    "* # None returned, no variants in common"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.merge(df_hbf, df_mal, how='inner', on=['Variation']) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---------------\r\n",
    "# PCA #\r\n",
    "\r\n",
    "----------\r\n",
    "### The following code segments were adapted from this author's interpretation during BMI 6332 Summer 2021 of Alistair Miles exploration of Fast PCA in scikit-allel found at https://alimanfoo.github.io/2015/09/28/fast-pca.html\r\n",
    "\r\n",
    "### Genomic data:\r\n",
    "    http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/ALL.wgs.phase3_shapeit2_mvncall_integrated_v5c.20130502.sites.vcf.gz\r\n",
    "\r\n",
    "### Population cluster sample annotation\r\n",
    "    http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/integrated_call_samples_v3.20200731.ALL.ped"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import random\r\n",
    "random.seed(42)\r\n",
    "import numpy as np\r\n",
    "np.random.seed(42)\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline\r\n",
    "import seaborn as sns\r\n",
    "sns.set_style('white')\r\n",
    "sns.set_style('ticks')\r\n",
    "import pandas as pd\r\n",
    "import allel"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Acquisition\r\n",
    "--------\r\n",
    "### Cell loads VCF"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "callset = allel.read_vcf('ALL.wgs.phase3_shapeit2_mvncall_integrated_v5c.20130502.sites.vcf.gz')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# gt_zarr = callset['calldata/GT']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Wrangling\r\n",
    "--------\r\n",
    "## Variants are retained according to specified GRCh37 positions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pos = allel.SortedIndex(callset['variants/POS'])\r\n",
    "loc_region = pos.locate_range(60677655, 60780789)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Wrangling\r\n",
    "--------\r\n",
    "### 1st cell loads genotype data in array (**gt**) + pulls allele count data into other array -> **ac**\r\n",
    "### 2nd cell Filters by MAF cutoff. Transforms array by return the highest allele index for each variant. Transforms each genotype cell into the number of non-reference alleles. \r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gt = allel.GenotypeArray(callset[loc_region])\r\n",
    "ac = gt.count_alleles()[:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "flt = (ac.max_allele() == 1) & (ac[:, :2].min(axis=1) > 5)\r\n",
    "\r\n",
    "gf = gt.compress(flt, axis=0)\r\n",
    "gn = gf.to_n_alt()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Analysis\r\n",
    "------\r\n",
    "### 1st cell is where SNP is randomly selected for PCA\r\n",
    "### 2nd cell is where the PCA is actually performed\r\n",
    "        n_components sets how many principal component (PCA fxn outputs) will be produced. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n = 100000\r\n",
    "vidx = np.random.choice(gn.shape[0], n, replace=False)\r\n",
    "vidx.sort()\r\n",
    "gnr = gn.take(vidx, axis=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "coords1, model1 = allel.pca(gnr, n_components=10, scaler='patterson')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Visualization\r\n",
    "----\r\n",
    "### 1st cell is where the 2 metadata files are merged to deliver \"Continental\" data, correlated to \"Population\"\r\n",
    "* \"Population\" - artificial label roughly defining pop sub group of sample -> \"Gujrati Indian from Houston\"\r\n",
    "* \"Continental\" - Categorizes \"Population\" sub groups into continent they emerge from\r\n",
    "\r\n",
    "### 2nd cell takes PCA output data and assigns metadata to each sample. Also assigns variables to be pulled for visualization."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_cont = pd.read_csv('continental.txt', delimiter='\\t', index_col='Population')\r\n",
    "\r\n",
    "df_samples = pd.read_csv('integrated_call_samples_v3.20200731.ALL.ped.txt', delimiter='\\t', index_col='Individual ID')\r\n",
    "df_samples = df_samples.join(df_cont, on='Population')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_gnu = pd.DataFrame(data=coords1, index=callset['samples'])\r\n",
    "pca_samples = df_gnu.join(df_samples)\r\n",
    "\r\n",
    "populations = pca_samples.Population.unique()\r\n",
    "continents = pca_samples.Continental.unique()\r\n",
    "cont_colours = plt.cm.rainbow(np.linspace(0, 1, len(continents)))\r\n",
    "pop_colours = plt.cm.rainbow(np.linspace(0, 1, len(populations)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Visualization (continued)\r\n",
    "----\r\n",
    "## Graphical output\r\n",
    "* 1st cell returns label and color information for samples and labels explained variance ratio for each principle component\r\n",
    "* 2nd cell returns Continental grouping PCA plots"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def plot_pca_coords(coords, model, pc1, pc2, ax, sample_population, pops, pop_colors):\r\n",
    "    sns.despine(ax=ax, offset=5)\r\n",
    "    x = coords[:, pc1]\r\n",
    "    y = coords[:, pc2]\r\n",
    "    for pop,color in zip(pops, pop_colors):\r\n",
    "        flt = (sample_population == pop)\r\n",
    "        ax.plot(x[flt], y[flt], marker='o', linestyle=' ', color=color, \r\n",
    "                label=pop, markersize=6, mec='k', mew=.5)\r\n",
    "    ax.set_xlabel('PC%s (%.1f%%)' % (pc1+1, model.explained_variance_ratio_[pc1]*100))\r\n",
    "    ax.set_ylabel('PC%s (%.1f%%)' % (pc2+1, model.explained_variance_ratio_[pc2]*100))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def fig_pca_cont(axl, ax2, coords, model, title, sample_population = None):\r\n",
    "    if sample_population is None:\r\n",
    "        sample_population = pca_samples.Continental.values\r\n",
    "    plot_pca_coords(coords, model, 0, 1, axl, sample_population, continents, cont_colours)\r\n",
    "    plot_pca_coords(coords, model, 2, 3, ax2, sample_population, continents, cont_colours)\r\n",
    "    ax2.legend(bbox_to_anchor=(1, 1), loc= 'upper left')\r\n",
    "    fig.suptitle(title, y=1.02)\r\n",
    "    fig.tight_layout()\r\n",
    "\r\n",
    "fig= plt.figure(figsize=(10, 5))\r\n",
    "axl = fig.add_subplot(1, 2, 1)\r\n",
    "ax2 = fig.add_subplot(1, 2, 2)\r\n",
    "\r\n",
    "fig_pca_cont(axl, ax2, coords1, model1, 'Figure 1. Continental PCA.')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LD Pruning\r\n",
    "----\r\n",
    "### Removal of one SNP from correlated pairs in 5 iterations of a 500 SNP window.\r\n",
    "### Variants pruned from 100,000 to only 1,614"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ef ld_prune(gn, size, step, threshold=.1, n_iter=1):\r\n",
    "    for i in range(n_iter):\r\n",
    "        loc_unlinked = allel.locate_unlinked(gn, size=size, step=step, threshold=threshold)\r\n",
    "        n = np.count_nonzero(loc_unlinked)\r\n",
    "        n_remove = gn.shape[0] - n\r\n",
    "        print('iteration', i+1, 'retaining', n, 'removing', n_remove, 'variants')\r\n",
    "        gn = gn.compress(loc_unlinked, axis=0)\r\n",
    "    return gn\r\n",
    "\r\n",
    "gnu_prune = ld_prune(gnr, size=500, step=200, threshold=.1, n_iter=5) ### NOTE: Uncomment to test"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gnu_prune = gnu_prune[:]\r\n",
    "coords2, model2 = allel.pca(gnu_prune, n_components=10, scaler='patterson')\r\n",
    "#################################################################################################\r\n",
    "\r\n",
    "def fig_pca_cont_pruned(axl, ax2, coords, model, title, sample_population = None):\r\n",
    "    if sample_population is None:\r\n",
    "        sample_population = pca_samples.Continental.values\r\n",
    "    plot_pca_coords(coords, model, 0, 1, axl, sample_population, continents, cont_colours)\r\n",
    "    plot_pca_coords(coords, model, 2, 3, ax2, sample_population, continents, cont_colours)\r\n",
    "    ax2.legend(bbox_to_anchor=(1, 1), loc= 'upper left')\r\n",
    "    fig.suptitle(title, y=1.02)\r\n",
    "    fig.tight_layout()\r\n",
    "\r\n",
    "fig= plt.figure(figsize=(10, 5))\r\n",
    "axl = fig.add_subplot(1, 2, 1)\r\n",
    "ax2 = fig.add_subplot(1, 2, 2)\r\n",
    "\r\n",
    "####################################\r\n",
    "\r\n",
    "\r\n",
    "fig_pca_cont_pruned(axl, ax2, coords2, model2, 'Figure 2. Pruned Continental PCA.')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('thaq': virtualenv)"
  },
  "interpreter": {
   "hash": "bd619682c53b43d37bf776754faf2e07ae18fa515484083fe932c58bcaa80cbb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}